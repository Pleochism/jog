{"name":"Jog","body":"\r\n  JSON logging & reporting inspired by Loggly for node.js.\r\n\r\n## Installation\r\n\r\n    $ npm install jog\r\n\r\n## Features\r\n\r\n  - namespace support\r\n  - rich json documents\r\n  - log levels\r\n  - file store\r\n  - redis store\r\n  - document streaming\r\n  - tail -f like streaming\r\n  - CLI to tail and map / reduce logs\r\n\r\n## API\r\n\r\n### log.write(level, msg[, obj])\r\n\r\n  Write to the logs:\r\n\r\n```js\r\nlog.write(level, msg[, obj])\r\nlog.debug(msg[, obj])\r\nlog.info(msg[, obj])\r\nlog.warn(msg[, obj])\r\nlog.error(msg[, obj])\r\n```\r\n\r\n### log.ns(obj)\r\n\r\n  Namespace with the given `obj`, returning a new `Jog` instance\r\n  inheriting previous properties. You may call this several times\r\n  to produce more and more specific loggers.\r\n\r\n```js\r\nvar log = jog(new jog.FileStore('/tmp/log'));\r\n\r\n// log a user 5\r\nlog = log.ns({ uid: 5 });\r\n\r\n// log video id 99 for user 5\r\nlog = log.ns({ vid: 99 });\r\n\r\n// or both at once\r\nlog = log.ns({ uid: 5, vid: 99 });\r\n```\r\n\r\n### log.stream(options)\r\n\r\n  Return an `EventEmitter` emitting \"data\" and \"end\" events.\r\n\r\n   - `end` when __false__ streaming will not end\r\n   - `interval` the interval at which to poll (store-specific)\r\n\r\n### log.clear(callback)\r\n\r\n  Clear the logs and invoke the callback.\r\n\r\n## Example\r\n\r\n  Log random data using the `FileStore` and tail the file\r\n  for changes (typically in different processes). Jog will add\r\n  the `.level` and `.msg` properties for you.\r\n\r\n```js\r\nvar jog = require('jog')\r\n  , log = jog(new jog.FileStore('/tmp/tail'))\r\n  , id = 0;\r\n\r\n// generate random log data\r\nfunction again() {\r\n  log.info('something happened', { id: ++id, user: 'Tobi' });\r\n  setTimeout(again, Math.random() * 100 | 0);\r\n}\r\n\r\nagain();\r\n\r\n// tail the json \"documents\"\r\nlog.stream({ end: false, interval: 500 })\r\n  .on('data', function(obj){\r\n    console.log(obj);\r\n  });\r\n```\r\n\r\nyields:\r\n\r\n```js\r\n{ id: 1,\r\n  level: 'info',\r\n  msg: 'something happened',\r\n  timestamp: 1332907641734 }\r\n{ id: 2,\r\n  level: 'info',\r\n  msg: 'something happened',\r\n  timestamp: 1332907641771 }\r\n...\r\n```\r\n\r\n## jog(1)\r\n\r\n```\r\n  Usage: jog [options]\r\n\r\n  Options:\r\n\r\n    -h, --help         output usage information\r\n    -V, --version      output the version number\r\n    -F, --file <path>  load from the given <path>\r\n    -R, --redis        load from redis store\r\n    -s, --select <fn>  use the given <fn> for filtering\r\n    -m, --map <fn>     use the given <fn> for mapping\r\n    -c, --color        enable colors for json output\r\n```\r\n\r\n### Examples\r\n\r\n  View all logs from tobi. The `_` object for the function\r\n  bodies of `--select` and `--map` represents the current\r\n  document, it's all just javascript.\r\n\r\n```\r\njog --file /tmp/jog --select \"_.user == 'tobi'\"\r\n[ { user: 'tobi',\r\n    duration: 1000,\r\n    level: 'info',\r\n    msg: 'rendering video',\r\n    timestamp: 1332861272100 },\r\n  { user: 'tobi',\r\n    duration: 2000,\r\n    level: 'info',\r\n    msg: 'compiling video',\r\n    timestamp: 1332861272100 },\r\n...\r\n```\r\n\r\n  Filter video compilation durations from \"tobi\" only:\r\n  \r\n```\r\n$ jog --file /var/log/videos.log --select \"_.user == 'tobi'\" --map _.duration\r\n[ 1000, 2000, 1200, 1000, 2000, 1200 ]\r\n```\r\n\r\n  The --map flag can be used several times:\r\n\r\n```\r\njog --file /var/log/videos.log --select \"_.vid < 5\" --map _.msg --map \"_.split(' ')\"\r\n[ [ 'compiling', 'video' ],\r\n  [ 'compiling', 'video' ],\r\n  [ 'compiling', 'video' ],\r\n  [ 'compiling', 'video' ] ]\r\n```\r\n\r\n## Stores\r\n\r\n  By default Jog ships with the `FileStore` and `RedisStore`, however anything\r\n  with the following methods implemented will work:\r\n  \r\n    - `add(obj)` to add a log object\r\n    - `stream() => EventEmitter` to stream data\r\n    - `stream({ end: false }) => EventEmitter` to stream data indefinitely\r\n    - `clear(fn)` to clear the logs\r\n\r\n### FileStore(path)\r\n\r\n  Store logs on disk.\r\n\r\n```js\r\nvar jog = require('jog');\r\nvar log = jog(new jog.FileStore('/var/log/videos.log'));\r\n```\r\n\r\n### RedisStore([client])\r\n\r\n  Store logs in redis.\r\n\r\n```js\r\nvar jog = require('jog');\r\nvar log = jog(new jog.RedisStore);\r\n```\r\n\r\n## Performance\r\n\r\n  No profiling or optimizations yet but the `FileStore` can\r\n  stream back 250,000 documents (~21MB) in 1.2 seconds on my\r\n  macbook air.\r\n\r\n  The `RedisStore` with 250,000 documents streamed back\r\n  in 2.8 seconds on my air.\r\n\r\n## Running tests\r\n\r\n```\r\n$ npm install\r\n$ redis-server &\r\n$ make test\r\n```","tagline":"JSON document logging & reporting inspired by loggly for node.js","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}